{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e0d006-3eac-4f0a-823d-a46fc9a0a609",
   "metadata": {},
   "source": [
    "### Q1. Difference Between Linear Regression and Logistic Regression:\n",
    "\n",
    "- **Linear Regression:**\n",
    "  - **Objective:** Predict a continuous numerical outcome.\n",
    "  - **Output:** Predicted values can range from negative to positive infinity.\n",
    "  - **Example:** Predicting house prices based on features like square footage and number of bedrooms.\n",
    "\n",
    "- **Logistic Regression:**\n",
    "  - **Objective:** Classify data into two or more categories.\n",
    "  - **Output:** Produces probabilities between 0 and 1 using the logistic function (sigmoid).\n",
    "  - **Example:** Predicting whether an email is spam (1) or not spam (0) based on features.\n",
    "\n",
    "**Scenario for Logistic Regression:**\n",
    "Suppose you want to predict whether a student passes (1) or fails (0) an exam based on study hours. Logistic regression would be more appropriate here as it deals with binary classification problems.\n",
    "\n",
    "### Q2. Cost Function and Optimization in Logistic Regression:\n",
    "\n",
    "- **Cost Function (Log Loss):**\n",
    "  - Measures the difference between predicted probabilities and actual class labels.\n",
    "  - **Formula:** \\( J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)}\\log(h_\\theta(x^{(i)})) + (1 - y^{(i)})\\log(1 - h_\\theta(x^{(i)}))] \\)\n",
    "  \n",
    "- **Optimization:**\n",
    "  - Gradient Descent or advanced optimization algorithms are used to minimize the cost function.\n",
    "  - Adjust model parameters (\\(\\theta\\)) iteratively to converge to the minimum.\n",
    "\n",
    "### Q3. Regularization in Logistic Regression:\n",
    "\n",
    "- **Concept:**\n",
    "  - Helps prevent overfitting by penalizing large coefficients.\n",
    "  - Two types: L1 regularization (Lasso) and L2 regularization (Ridge).\n",
    "\n",
    "### Q4. ROC Curve for Logistic Regression:\n",
    "\n",
    "- **ROC Curve:**\n",
    "  - Receiver Operating Characteristic curve.\n",
    "  - Plots the true positive rate against the false positive rate at various classification thresholds.\n",
    "  - Evaluates the model's ability to discriminate between positive and negative classes.\n",
    "\n",
    "### Q5. Feature Selection Techniques in Logistic Regression:\n",
    "\n",
    "- **Common Techniques:**\n",
    "  - Recursive Feature Elimination (RFE).\n",
    "  - L1 regularization (Lasso) to induce sparsity.\n",
    "  - Feature importance from tree-based models.\n",
    "\n",
    "- **Improvements:**\n",
    "  - Enhance model interpretability.\n",
    "  - Reduce dimensionality and computational complexity.\n",
    "\n",
    "### Q6. Handling Imbalanced Datasets:\n",
    "\n",
    "- **Strategies:**\n",
    "  - Resampling techniques (oversampling minority, undersampling majority).\n",
    "  - Using different evaluation metrics (precision, recall, F1-score).\n",
    "  - Ensemble methods like SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "### Q7. Common Issues and Challenges:\n",
    "\n",
    "- **Multicollinearity:**\n",
    "  - Detect using variance inflation factor (VIF).\n",
    "  - Address by removing correlated variables or using regularization.\n",
    "\n",
    "- **Outliers:**\n",
    "  - Identify and handle outliers to prevent undue influence on the model.\n",
    "\n",
    "- **Non-Linearity:**\n",
    "  - Address by incorporating non-linear terms or using non-linear models.\n",
    "\n",
    "- **Interpretability:**\n",
    "  - Logistic regression coefficients may not always have direct interpretability.\n",
    "\n",
    "Addressing these challenges involves a combination of statistical techniques and domain-specific considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01539f-2ba0-40de-8def-0f47a74a9c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
